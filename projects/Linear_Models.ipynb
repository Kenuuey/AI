{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Q&A "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Analytical Solution to the Regression Problem (Vector Form)\n",
    "\n",
    "**The Loss Function (MSE)** in linear regression is defined as the squared norm of the residuals between the predicted and actual values:\n",
    "\n",
    "$$L(w) = ||Xw - y||^2$$\n",
    "\n",
    "Where:\n",
    "- X is the design matrix of input features of shape n x m with n being the number of samples and m the number of features.\n",
    "- w is the vector of weights of shape m x 1.\n",
    "- y is the target vector of shape n x 1.\n",
    "\n",
    "The norm $||\\cdot||^2$ is the **squared Euclidean norm**, which is equivalent to the dot product of the vector with itself, hence:\n",
    "\n",
    "$$L(w) = (Xw - y)^T(Xw -y)$$\n",
    "\n",
    "Apply the distributive property:\n",
    "\n",
    "$$L(w)= (Xw)^T (Xw) - (Xw)^T y - y^T (Xw) + y^T y$$\n",
    "\n",
    "Since $(Xw)^Ty$ is a scalar (a single number), and scalars are equal to their transpose:\n",
    "\n",
    "$$L(w)= w^T X^T X w - 2 y^T X w + y^T y$$\n",
    "\n",
    "To find the optimal weights, we need to take the derivative of the loss function with respect to w:\n",
    "\n",
    "$$\\frac{\\partial L(w)}{\\partial w} = 2 X^T X w - 2 X^T y$$\n",
    "\n",
    "Set the derivative to zero:\n",
    "\n",
    "$$2 X^T X w - 2 X^T y = 0$$\n",
    "\n",
    "Simplify:\n",
    "\n",
    "$$X^T X w = X^T y$$\n",
    "\n",
    "Solve for w: \n",
    "<!-- assuming $$X^T X$$ is invertible: -->\n",
    "$$w = (X^T X)^{-1} X^T y$$\n",
    "\n",
    "This is the **Normal Equation** for linear regression.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Changes When L1 and L2 Regularizations Are Added\n",
    "\n",
    "**L1 Regularization (Lasso Regression)**\n",
    "\n",
    "Adds the sum of the absolute values of the weights to the loss function:\n",
    "\n",
    "$$L(w) = ||Xw - y||^2 + \\lambda ||w||_1$$\n",
    "\n",
    "Where $||w||_1$ is the L1 norm:\n",
    "\n",
    "$$||w||_1 = \\sum_{i=1}^{m} |w_i|$$\n",
    "\n",
    "L1 regularization encourages sparsity in the model weights, i.e., many weights become exactly zero.\n",
    "\n",
    "**L2 Regularization (Ridge Regression)**\n",
    "\n",
    "Adds the sum of the squared values of the weights to the loss function:\n",
    "\n",
    "$$L(w) = ||Xw - y||^2 + \\lambda ||w||_2^2$$\n",
    "\n",
    "Where $||w||_2^2$ is the squared L2 norm:\n",
    "\n",
    "$$||w||_2^2 = \\sum_{i=1}^{m} w_i^2$$\n",
    "\n",
    "L2 regularization penalizes large weight values but does not set them exactly to zero.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Why is L1 Regularization Often Used for Feature Selection?\n",
    "\n",
    "L1 regularization encourages sparsity in the weight vector because it applies equal penalty regardless of the weight sign. The optimization process often drives some weights to exactly **0**, effectively excluding the corresponding features from the model.\n",
    "\n",
    "**Why Many Weights are 0 After Model Fitting**\n",
    "- L1 regularization creates a sharp corner at zero in the loss function landscape, leading to many coefficients being driven precisely to zero.\n",
    "- This results in a sparse model that selects only the most relevant features.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Using Linear Models for Nonlinear Dependencies\n",
    "\n",
    "Linear models such as Linear Regression, Ridge, and Lasso can handle nonlinear relationships by transforming the input features. Some common techniques include:\n",
    "\n",
    "**Feature Engineering with Polynomial Features**\n",
    "\n",
    "Transform the original features into polynomial terms:\n",
    "\n",
    "$$x_1, x_1^2, x_2, x_1 \\cdot x_2, \\dots$$\n",
    "\n",
    "This can be done using libraries such as `PolynomialFeatures` from `sklearn.preprocessing`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Introduction - preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_json('./data/train.json')\n",
    "df_test = pd.read_json('./data/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49352, 15)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659, 14)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns in test dataset: {'interest_level'}\n"
     ]
    }
   ],
   "source": [
    "missing_cols = set(df_train.columns) - set(df_test.columns)\n",
    "print('Missing columns in test dataset:', missing_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     medium\n",
       "6        low\n",
       "9     medium\n",
       "10    medium\n",
       "15       low\n",
       "Name: interest_level, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['interest_level'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'low': 0, 'medium': 1, 'high': 2}\n",
    "df_train['interest_level'] = df_train['interest_level'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     1\n",
       "6     0\n",
       "9     1\n",
       "10    1\n",
       "15    0\n",
       "Name: interest_level, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['interest_level'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['interest_level'] = np.zeros(len(df_test)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "5    0\n",
       "Name: interest_level, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['interest_level'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659, 15)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data analysis part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4         [Dining Room, Pre-War, Laundry in Building, Di...\n",
       "6         [Doorman, Elevator, Laundry in Building, Dishw...\n",
       "9         [Doorman, Elevator, Laundry in Building, Laund...\n",
       "10                                                       []\n",
       "15        [Doorman, Elevator, Fitness Center, Laundry in...\n",
       "                                ...                        \n",
       "124000              [Elevator, Dishwasher, Hardwood Floors]\n",
       "124002    [Common Outdoor Space, Cats Allowed, Dogs Allo...\n",
       "124004    [Dining Room, Elevator, Pre-War, Laundry in Bu...\n",
       "124008    [Pre-War, Laundry in Unit, Dishwasher, No Fee,...\n",
       "124009    [Dining Room, Elevator, Laundry in Building, D...\n",
       "Name: features, Length: 49352, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49352, 15)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659, 15)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unused symbols ([,], ', \", and space) from the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['features'] = df_train['features'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "df_train['features'] = df_train['features'].replace(r\"[\\[\\]'\\\"]\", \"\", regex=True)\n",
    "\n",
    "df_test['features'] = df_test['features'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "df_test['features'] = df_test['features'].replace(r\"[\\[\\]'\\\"]\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split values in each row with the separator \",\" and collect the result in one huge list for the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = []\n",
    "for _, row in df_train.iterrows():\n",
    "    features = row['features'].split(',') if isinstance(row['features'], str) else []\n",
    "    all_features.extend([feature.strip() for feature in features if feature.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267906"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique values does a result list contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1553"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_features = set(all_features)\n",
    "len(unique_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the most popular functions from our huge list and take the top 20 for this moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "feature_counts = Counter(all_features)\n",
    "top_20_features = feature_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Elevator', 25915),\n",
       " ('Cats Allowed', 23540),\n",
       " ('Hardwood Floors', 23527),\n",
       " ('Dogs Allowed', 22035),\n",
       " ('Doorman', 20898),\n",
       " ('Dishwasher', 20426),\n",
       " ('No Fee', 18062),\n",
       " ('Laundry in Building', 16344),\n",
       " ('Fitness Center', 13252),\n",
       " ('Pre-War', 9148),\n",
       " ('Laundry in Unit', 8738),\n",
       " ('Roof Deck', 6542),\n",
       " ('Outdoor Space', 5268),\n",
       " ('Dining Room', 5136),\n",
       " ('High Speed Internet', 4299),\n",
       " ('Balcony', 2992),\n",
       " ('Swimming Pool', 2730),\n",
       " ('Laundry In Building', 2593),\n",
       " ('New Construction', 2559),\n",
       " ('Terrace', 2283)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, _ in top_20_features:\n",
    "  df_train[feature] = df_train['features'].apply(lambda x: 1 if feature in x else 0) \n",
    "  df_test[feature] = df_test['features'].apply(lambda y: 1 if feature in y else 0) \n",
    "\n",
    "top_20_feature_names = [feature_name for feature_name, _ in top_20_features]\n",
    "additional_features = ['bathrooms', 'bedrooms', 'interest_level']\n",
    "\n",
    "feature_list = top_20_feature_names + additional_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'price'\n",
    "\n",
    "X_train = df_train[feature_list]\n",
    "y_train = df_train[target]\n",
    "\n",
    "X_test = df_test[feature_list]\n",
    "y_test = df_test[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Models implementation — Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionSGD():\n",
    "  def __init__(self, learning_rate=0.01, n_epochs=10):\n",
    "    self.learning_rate = learning_rate\n",
    "    self.n_epochs = n_epochs\n",
    "    self.weights = None\n",
    "    self.bias = 0\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    n_samples, n_features = X.shape\n",
    "    self.weights = np.zeros(n_features)\n",
    "\n",
    "    # Stochastic gradient descent\n",
    "    for epoch in range(self.n_epochs):\n",
    "      for i in range(n_samples):\n",
    "        # Prediction for current sample\n",
    "        y_pred = np.dot(X[i], self.weights) + self.bias\n",
    "\n",
    "        # Calculate gradients\n",
    "        error = y_pred - y[i]\n",
    "        dW = 2 * X[i] * error\n",
    "        db = 2 * error\n",
    "\n",
    "        # Update weights and bias\n",
    "        self.weights -= self.learning_rate * dW\n",
    "        self.bias -= self.learning_rate * db\n",
    "\n",
    "  def predict(self, X):\n",
    "    X = np.array(X)\n",
    "    return np.dot(X, self.weights) + self.bias\n",
    "  \n",
    "\n",
    "class LinearRegressionAnalytical():\n",
    "    def __init__(self):\n",
    "      self.weights = None\n",
    "      self.bias = 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "      X = np.array(X)\n",
    "      y = np.array(y)\n",
    "\n",
    "      # Analytical solution using Normal Equation\n",
    "      X_b = np.c_[np.ones((X.shape[0], 1)), X]  # Add bias column\n",
    "      self.weights = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "      X = np.array(X)\n",
    "      X_b = np.c_[np.ones((X.shape[0], 1)), X]  # Add bias column\n",
    "      return X_b.dot(self.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "  ss_total = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "  ss_residual = np.sum((y_true - y_pred) ** 2)\n",
    "  r2 = (1 - (ss_residual / ss_total))\n",
    "  return r2\n",
    "\n",
    "def train_predict_and_evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        \"MAE\": (mean_absolute_error(y_train, y_train_pred), mean_absolute_error(y_test, y_test_pred)),\n",
    "        \"RMSE\": (root_mean_squared_error(y_train, y_train_pred), root_mean_squared_error(y_test, y_test_pred)),\n",
    "        \"R2\": (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred))\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD: Training and evaluation completed\n",
      "Analytical: Training and evaluation completed\n",
      "Sklearn: Training and evaluation completed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression as SklearnLinearRegression\n",
    "\n",
    "models = [\n",
    "    ('SGD', LinearRegressionSGD()),\n",
    "    ('Analytical', LinearRegressionAnalytical()),\n",
    "    ('Sklearn', SklearnLinearRegression())\n",
    "]\n",
    "\n",
    "results_1 = {metric: {'Model': [], 'Train': [], 'Test': []} for metric in [\"MAE\", \"RMSE\", \"R2\"]}\n",
    "\n",
    "# Train models and store results\n",
    "for model_name, model in models:\n",
    "    metrics = train_predict_and_evaluate(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    for metric, values in metrics.items():\n",
    "        results_1[metric]['Model'].append(model_name)\n",
    "        results_1[metric]['Train'].append(values[0])\n",
    "        results_1[metric]['Test'].append(values[1])\n",
    "\n",
    "    print(f'{model_name}: Training and evaluation completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Absolute Error (MAE):\n",
      "         Model        Train         Test\n",
      "0         SGD  1660.872537  1617.860103\n",
      "1  Analytical  1135.890034  1123.607781\n",
      "2     Sklearn  1135.890034  1123.607781\n",
      "\n",
      "Root Mean Squared Error (RMSE):\n",
      "         Model         Train         Test\n",
      "0         SGD  22037.194417  9705.770805\n",
      "1  Analytical  21992.794926  9618.787306\n",
      "2     Sklearn  21992.794926  9618.787306\n",
      "\n",
      "R2 Score:\n",
      "         Model     Train      Test\n",
      "0         SGD  0.002667  0.001493\n",
      "1  Analytical  0.006682  0.019311\n",
      "2     Sklearn  0.006682  0.019311\n"
     ]
    }
   ],
   "source": [
    "results_MAE = pd.DataFrame(results_1[\"MAE\"])\n",
    "results_RMSE = pd.DataFrame(results_1[\"RMSE\"])\n",
    "results_R2Score = pd.DataFrame(results_1[\"R2\"])\n",
    "\n",
    "print(\"\\nMean Absolute Error (MAE):\\n\", results_MAE)\n",
    "print(\"\\nRoot Mean Squared Error (RMSE):\\n\", results_RMSE)\n",
    "print(\"\\nR2 Score:\\n\", results_R2Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Regularized models implementation — Ridge, Lasso, ElasticNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression:\n",
    "    def __init__(self, alpha=1.0, learning_rate=0.01, epochs=1000):\n",
    "        self.alpha = alpha  # Regularization strength (L2)\n",
    "        self.learning_rate = learning_rate  # Learning rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            y_pred = np.dot(X, self.weights) + self.bias\n",
    "            dw = (1 / n_samples) * (np.dot(X.T, (y_pred - y)) + self.alpha * self.weights)\n",
    "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
    "\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "\n",
    "\n",
    "class LassoRegression:\n",
    "    def __init__(self, alpha=1.0, learning_rate=0.01, epochs=1000):\n",
    "        self.alpha = alpha  # Regularization strength (L1)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            y_pred = np.dot(X, self.weights) + self.bias\n",
    "            dw = (1 / n_samples) * (np.dot(X.T, (y_pred - y))) + self.alpha * np.sign(self.weights)  # L1 term\n",
    "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
    "\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "\n",
    "\n",
    "class ElasticNetRegression:\n",
    "    def __init__(self, alpha=1.0, l1_ratio=0.5, learning_rate=0.01, epochs=1000):\n",
    "        self.alpha = alpha  # Regularization strength\n",
    "        self.l1_ratio = l1_ratio  # L1 vs L2 ratio\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            y_pred = np.dot(X, self.weights) + self.bias\n",
    "            l1_term = self.l1_ratio * np.sign(self.weights)  # L1\n",
    "            l2_term = (1 - self.l1_ratio) * self.weights  # L2\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y)) + self.alpha * (l1_term + l2_term)\n",
    "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
    "\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge (Custom): Training and evaluation completed\n",
      "Lasso (Custom): Training and evaluation completed\n",
      "ElasticNet (Custom): Training and evaluation completed\n",
      "Ridge (Sklearn): Training and evaluation completed\n",
      "Lasso (Sklearn): Training and evaluation completed\n",
      "ElasticNet (Sklearn): Training and evaluation completed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "\n",
    "models = [\n",
    "    ('Ridge (Custom)', RidgeRegression(alpha=1.0)),\n",
    "    ('Lasso (Custom)', LassoRegression(alpha=1.0)),\n",
    "    ('ElasticNet (Custom)', ElasticNetRegression(alpha=1.0, l1_ratio=0.5)),\n",
    "    ('Ridge (Sklearn)', Ridge(alpha=1.0)),\n",
    "    ('Lasso (Sklearn)', Lasso(alpha=1.0)),\n",
    "    ('ElasticNet (Sklearn)', ElasticNet(alpha=1.0, l1_ratio=0.5))\n",
    "]\n",
    "\n",
    "results_2 = {metric: {'Model': [], 'Train': [], 'Test': []} for metric in [\"MAE\", \"RMSE\", \"R2\"]}\n",
    "\n",
    "# Train models and store results\n",
    "for model_name, model in models:\n",
    "    metrics = train_predict_and_evaluate(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    for metric, values in metrics.items():\n",
    "        results_2[metric]['Model'].append(model_name)\n",
    "        results_2[metric]['Train'].append(values[0])\n",
    "        results_2[metric]['Test'].append(values[1])\n",
    "\n",
    "    print(f'{model_name}: Training and evaluation completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Absolute Error (MAE):\n",
      "                   Model        Train         Test\n",
      "0        Ridge (Custom)  1097.540267  1112.070263\n",
      "1        Lasso (Custom)  1095.980136  1111.063318\n",
      "2   ElasticNet (Custom)  1066.756122  1075.869141\n",
      "3       Ridge (Sklearn)  1135.844098  1123.574955\n",
      "4       Lasso (Sklearn)  1132.050014  1120.776753\n",
      "5  ElasticNet (Sklearn)  1090.801634  1108.878278\n",
      "\n",
      "Root Mean Squared Error (RMSE):\n",
      "                   Model         Train         Test\n",
      "0        Ridge (Custom)  21994.203113  9611.089481\n",
      "1        Lasso (Custom)  21994.249651  9611.049927\n",
      "2   ElasticNet (Custom)  22010.835837  9610.589277\n",
      "3       Ridge (Sklearn)  21992.794927  9618.778133\n",
      "4       Lasso (Sklearn)  21992.804021  9618.658296\n",
      "5  ElasticNet (Sklearn)  22012.208427  9613.895725\n",
      "\n",
      "R2 Score:\n",
      "                   Model     Train      Test\n",
      "0        Ridge (Custom)  0.006555  0.020880\n",
      "1        Lasso (Custom)  0.006551  0.020888\n",
      "2   ElasticNet (Custom)  0.005052  0.020982\n",
      "3       Ridge (Sklearn)  0.006682  0.019312\n",
      "4       Lasso (Sklearn)  0.006681  0.019337\n",
      "5  ElasticNet (Sklearn)  0.004928  0.020308\n"
     ]
    }
   ],
   "source": [
    "df_MAE = pd.DataFrame(results_2[\"MAE\"])\n",
    "df_RMSE = pd.DataFrame(results_2[\"RMSE\"])\n",
    "df_R2 = pd.DataFrame(results_2[\"R2\"])\n",
    "\n",
    "print(\"\\nMean Absolute Error (MAE):\\n\", df_MAE)\n",
    "print(\"\\nRoot Mean Squared Error (RMSE):\\n\", df_RMSE)\n",
    "print(\"\\nR2 Score:\\n\", df_R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Feature normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When is Feature Normalization Mandatory?\n",
    "\n",
    "1. Gradient Descent Optimization\n",
    "\n",
    "   - If features are on different scales, gradient descent might converge slowly or get stuck.\n",
    "   - Example: Predicting house prices with area (sq ft) ranging from 500–5000 and number of bedrooms ranging from 1–5.\n",
    "\n",
    "2. Distance-Based Algorithms (e.g., KNN, K-Means)\n",
    "\n",
    "   - Features with larger scales dominate distance computations, leading to biased results.\n",
    "   - Example: In K-Nearest Neighbors (KNN), Euclidean distance depends on feature magnitude.\n",
    "\n",
    "\n",
    "When is Feature Normalization NOT Needed?\n",
    "\n",
    "1. Tree-Based Models (e.g., Decision Trees, Random Forest, XGBoost)\n",
    "\n",
    "   - Tree models split on feature values rather than using distances or gradients, so scaling doesn’t impact performance.\n",
    "\n",
    "2. Already Normalized Data\n",
    "\n",
    "   - If the data is already on a similar scale (e.g., percentages ranging from 0 to 100), normalization may not be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Min-Max Scaling**\n",
    "\n",
    "The **MinMaxScaler** rescales features to a range of **[0,1]** using the following formula:\n",
    "\n",
    "$$X_{\\text{scaled}} = \\frac{X - X_{\\min}}{X_{\\max} - X_{\\min}}$$\n",
    "\n",
    "- $X_{min}$ : Minimum value of the feature  \n",
    "- $X_{max}$ : Maximum value of the feature  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class MinMax_Scaler():\n",
    "    def __init__(self):\n",
    "        self.X_min = None\n",
    "        self.X_max = None\n",
    "    \n",
    "    def fit_transform(self, X_train):\n",
    "        self.X_min = np.min(X_train, axis = 0)\n",
    "        self.X_max = np.max(X_train, axis = 0)\n",
    "        X_scaled = (X_train - self.X_min) / (self.X_max - self.X_min)\n",
    "        return X_scaled\n",
    "    \n",
    "    def transform(self, X_test):\n",
    "        X_scaled = (X_test - self.X_min) / (self.X_max - self.X_min)\n",
    "        return X_scaled\n",
    "\n",
    "# Custom\n",
    "custom_scaler = MinMax_Scaler()\n",
    "X_train_scaled_custom = custom_scaler.fit_transform(X_train)\n",
    "X_test_scaled_custom = custom_scaler.transform(X_test)\n",
    "\n",
    "# Sklearn method\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled_sklearn = scaler.fit_transform(X_train)\n",
    "X_test_scaled_sklearn = scaler.transform(X_test)\n",
    "\n",
    "print(np.allclose(X_train_scaled_custom, X_train_scaled_sklearn))\n",
    "print(np.allclose(X_test_scaled_custom, X_test_scaled_sklearn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class Standard_Scaler:\n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "\n",
    "    def fit_transform(self, X_train):\n",
    "        self.mean = np.mean(X_train, axis=0)\n",
    "        self.std = np.std(X_train, axis=0)\n",
    "        X_scaled = (X_train - self.mean) / self.std\n",
    "        return X_scaled\n",
    "\n",
    "    def transform(self, X_test):\n",
    "        X_scaled = (X_test - self.mean) / self.std\n",
    "        return X_scaled\n",
    "\n",
    "# Custom\n",
    "scaler_custom = Standard_Scaler()\n",
    "X_train_standardized_custom = scaler_custom.fit_transform(X_train)\n",
    "X_test_standardized_custom = scaler_custom.transform(X_test)\n",
    "\n",
    "# Sklearn method\n",
    "scaler_std = StandardScaler()\n",
    "X_train_standardized_sklearn = scaler_std.fit_transform(X_train)\n",
    "X_test_standardized_sklearn = scaler_std.transform(X_test)\n",
    "\n",
    "print(np.allclose(X_train_standardized_custom, X_train_standardized_sklearn))\n",
    "print(np.allclose(X_test_standardized_custom, X_test_standardized_sklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Fit models with normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_and_evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        \"MAE\": (mean_absolute_error(y_train, y_train_pred), mean_absolute_error(y_test, y_test_pred)),\n",
    "        \"RMSE\": (root_mean_squared_error(y_train, y_train_pred), root_mean_squared_error(y_test, y_test_pred)),\n",
    "        \"R2\": (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred))\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def machine_learning(scalers, models, results):\n",
    "  for scaler_name, scaler in scalers.items():\n",
    "    for model_name, model in models:\n",
    "      \n",
    "          if scaler_name == 'Default':\n",
    "              metrics = train_predict_and_evaluate(model, X_train, y_train, X_test, y_test)\n",
    "          \n",
    "          elif scaler_name == 'MinMaxScaler' or scaler_name == 'StandardScaler':\n",
    "              X_train_scaled = scaler.fit_transform(X_train)\n",
    "              X_test_scaled = scaler.transform(X_test)\n",
    "              metrics = train_predict_and_evaluate(model, X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "         \n",
    "          elif scaler_name == 'Polynomial':\n",
    "              X_train_poly = scaler.fit_transform(X_train[['bathrooms', 'bedrooms', 'interest_level']])\n",
    "              X_test_poly = scaler.transform(X_test[['bathrooms', 'bedrooms', 'interest_level']])\n",
    "              metrics = train_predict_and_evaluate(model, X_train_poly, y_train, X_test_poly, y_test)\n",
    "          \n",
    "          for metric, values in metrics.items():\n",
    "              results[metric]['Model'].append(model_name + f' {scaler_name}')\n",
    "              results[metric]['Train'].append(values[0])\n",
    "              results[metric]['Test'].append(values[1])\n",
    "\n",
    "          print(f'{model_name} {scaler_name}: Training and evaluation completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linreg Default: Training and evaluation completed\n",
      "Ridge Default: Training and evaluation completed\n",
      "Lasso Default: Training and evaluation completed\n",
      "ElasticNet Default: Training and evaluation completed\n",
      "Linreg MinMaxScaler: Training and evaluation completed\n",
      "Ridge MinMaxScaler: Training and evaluation completed\n",
      "Lasso MinMaxScaler: Training and evaluation completed\n",
      "ElasticNet MinMaxScaler: Training and evaluation completed\n",
      "Linreg StandardScaler: Training and evaluation completed\n",
      "Ridge StandardScaler: Training and evaluation completed\n",
      "Lasso StandardScaler: Training and evaluation completed\n",
      "ElasticNet StandardScaler: Training and evaluation completed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "models = [\n",
    "    ('Linreg', LinearRegression()),\n",
    "    ('Ridge', Ridge()),\n",
    "    ('Lasso', Lasso()),\n",
    "    ('ElasticNet', ElasticNet())\n",
    "]\n",
    "\n",
    "scalers = {\n",
    "    'Default': None,\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'StandardScaler': StandardScaler()\n",
    "}\n",
    "\n",
    "results = {metric: {'Model': [], 'Train': [], 'Test': []} for metric in [\"MAE\", \"RMSE\", \"R2\"]}\n",
    "\n",
    "machine_learning(scalers, models, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAE Results:\n",
      "                         Model        Train         Test\n",
      "0              Linreg Default  1135.890034  1123.607781\n",
      "1               Ridge Default  1135.844098  1123.574955\n",
      "2               Lasso Default  1132.050014  1120.776753\n",
      "3          ElasticNet Default  1090.801634  1108.878278\n",
      "4         Linreg MinMaxScaler  1135.890034  1123.607781\n",
      "5          Ridge MinMaxScaler  1135.838563  1123.883187\n",
      "6          Lasso MinMaxScaler  1131.372213  1120.726491\n",
      "7     ElasticNet MinMaxScaler  1436.094703  1389.342907\n",
      "8       Linreg StandardScaler  1135.890034  1123.607781\n",
      "9        Ridge StandardScaler  1135.879137  1123.599364\n",
      "10       Lasso StandardScaler  1134.175075  1122.270001\n",
      "11  ElasticNet StandardScaler  1051.474456  1066.145360\n",
      "\n",
      "RMSE Results:\n",
      "                         Model         Train         Test\n",
      "0              Linreg Default  21992.794926  9618.787306\n",
      "1               Ridge Default  21992.794927  9618.778133\n",
      "2               Lasso Default  21992.804021  9618.658296\n",
      "3          ElasticNet Default  22012.208427  9613.895725\n",
      "4         Linreg MinMaxScaler  21992.794926  9618.787306\n",
      "5          Ridge MinMaxScaler  21992.797204  9617.988714\n",
      "6          Lasso MinMaxScaler  21992.812869  9617.142573\n",
      "7     ElasticNet MinMaxScaler  22050.168464  9685.211665\n",
      "8       Linreg StandardScaler  21992.794926  9618.787306\n",
      "9        Ridge StandardScaler  21992.794926  9618.785232\n",
      "10       Lasso StandardScaler  21992.796297  9618.708951\n",
      "11  ElasticNet StandardScaler  21998.635174  9602.965420\n",
      "\n",
      "R2 Results:\n",
      "                         Model     Train      Test\n",
      "0              Linreg Default  0.006682  0.019311\n",
      "1               Ridge Default  0.006682  0.019312\n",
      "2               Lasso Default  0.006681  0.019337\n",
      "3          ElasticNet Default  0.004928  0.020308\n",
      "4         Linreg MinMaxScaler  0.006682  0.019311\n",
      "5          Ridge MinMaxScaler  0.006682  0.019473\n",
      "6          Lasso MinMaxScaler  0.006680  0.019646\n",
      "7     ElasticNet MinMaxScaler  0.001493  0.005719\n",
      "8       Linreg StandardScaler  0.006682  0.019311\n",
      "9        Ridge StandardScaler  0.006682  0.019311\n",
      "10       Lasso StandardScaler  0.006682  0.019327\n",
      "11  ElasticNet StandardScaler  0.006154  0.022534\n"
     ]
    }
   ],
   "source": [
    "result_MAE = pd.DataFrame(results[\"MAE\"])\n",
    "result_RMSE = pd.DataFrame(results[\"RMSE\"])\n",
    "result_R2 = pd.DataFrame(results[\"R2\"])\n",
    "\n",
    "print(\"\\nMAE Results:\\n\", result_MAE)\n",
    "print(\"\\nRMSE Results:\\n\", result_RMSE)\n",
    "print(\"\\nR2 Results:\\n\", result_R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Overfit models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linreg Default: Training and evaluation completed\n",
      "Ridge Default: Training and evaluation completed\n",
      "Lasso Default: Training and evaluation completed\n",
      "ElasticNet Default: Training and evaluation completed\n",
      "Linreg MinMaxScaler: Training and evaluation completed\n",
      "Ridge MinMaxScaler: Training and evaluation completed\n",
      "Lasso MinMaxScaler: Training and evaluation completed\n",
      "ElasticNet MinMaxScaler: Training and evaluation completed\n",
      "Linreg StandardScaler: Training and evaluation completed\n",
      "Ridge StandardScaler: Training and evaluation completed\n",
      "Lasso StandardScaler: Training and evaluation completed\n",
      "ElasticNet StandardScaler: Training and evaluation completed\n",
      "Linreg Polynomial: Training and evaluation completed\n",
      "Ridge Polynomial: Training and evaluation completed\n",
      "Lasso Polynomial: Training and evaluation completed\n",
      "ElasticNet Polynomial: Training and evaluation completed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "models = [\n",
    "    ('Linreg', LinearRegression()),\n",
    "    ('Ridge', Ridge(alpha=1.0, max_iter=5000, tol=1e+7)),\n",
    "    ('Lasso', Lasso(alpha=0.01, max_iter=5000, tol=1e+7)),\n",
    "    ('ElasticNet', ElasticNet(alpha=0.01, max_iter=5000, tol=1e+7))\n",
    "]\n",
    "\n",
    "scalers = {\n",
    "    'Default': None,\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'Polynomial' : PolynomialFeatures(degree=3)\n",
    "}\n",
    "\n",
    "new_results = {metric: {'Model': [], 'Train': [], 'Test': []} for metric in [\"MAE\", \"RMSE\", \"R2\"]}\n",
    "\n",
    "machine_learning(scalers, models, new_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAE Results:\n",
      "                         Model        Train         Test\n",
      "0              Linreg Default  1135.890034  1123.607781\n",
      "1               Ridge Default  1135.844098  1123.574955\n",
      "2               Lasso Default  1215.067096  1190.027368\n",
      "3          ElasticNet Default  1203.315777  1181.054646\n",
      "4         Linreg MinMaxScaler  1135.890034  1123.607781\n",
      "5          Ridge MinMaxScaler  1135.838563  1123.883187\n",
      "6          Lasso MinMaxScaler  1215.038720  1190.006705\n",
      "7     ElasticNet MinMaxScaler  1178.110858  1190.503046\n",
      "8       Linreg StandardScaler  1135.890034  1123.607781\n",
      "9        Ridge StandardScaler  1135.879137  1123.599364\n",
      "10       Lasso StandardScaler  1215.087176  1190.043330\n",
      "11  ElasticNet StandardScaler  1212.664431  1188.129744\n",
      "12          Linreg Polynomial  1031.797352  4133.626544\n",
      "13           Ridge Polynomial  1031.725328  4124.360428\n",
      "14           Lasso Polynomial  1096.174484  1446.850512\n",
      "15      ElasticNet Polynomial  1094.056284  1452.540141\n",
      "\n",
      "RMSE Results:\n",
      "                         Model         Train           Test\n",
      "0              Linreg Default  21992.794926    9618.787306\n",
      "1               Ridge Default  21992.794927    9618.778133\n",
      "2               Lasso Default  22002.837189    9649.886886\n",
      "3          ElasticNet Default  22002.142296    9646.795689\n",
      "4         Linreg MinMaxScaler  21992.794926    9618.787306\n",
      "5          Ridge MinMaxScaler  21992.797204    9617.988714\n",
      "6          Lasso MinMaxScaler  22002.835247    9649.867352\n",
      "7     ElasticNet MinMaxScaler  22005.366435    9612.169091\n",
      "8       Linreg StandardScaler  21992.794926    9618.787306\n",
      "9        Ridge StandardScaler  21992.794926    9618.785232\n",
      "10       Lasso StandardScaler  22002.838402    9649.889343\n",
      "11  ElasticNet StandardScaler  22002.721892    9649.118854\n",
      "12          Linreg Polynomial  21992.233456  827183.937108\n",
      "13           Ridge Polynomial  21992.233563  824688.878414\n",
      "14           Lasso Polynomial  22004.522784   81672.450181\n",
      "15      ElasticNet Polynomial  22004.274444   83690.789694\n",
      "\n",
      "R2 Results:\n",
      "                         Model     Train         Test\n",
      "0              Linreg Default  0.006682     0.019311\n",
      "1               Ridge Default  0.006682     0.019312\n",
      "2               Lasso Default  0.005775     0.012959\n",
      "3          ElasticNet Default  0.005837     0.013591\n",
      "4         Linreg MinMaxScaler  0.006682     0.019311\n",
      "5          Ridge MinMaxScaler  0.006682     0.019473\n",
      "6          Lasso MinMaxScaler  0.005775     0.012963\n",
      "7     ElasticNet MinMaxScaler  0.005546     0.020660\n",
      "8       Linreg StandardScaler  0.006682     0.019311\n",
      "9        Ridge StandardScaler  0.006682     0.019311\n",
      "10       Lasso StandardScaler  0.005774     0.012958\n",
      "11  ElasticNet StandardScaler  0.005785     0.013116\n",
      "12          Linreg Polynomial  0.006733 -7251.621814\n",
      "13           Ridge Polynomial  0.006733 -7207.935217\n",
      "14           Lasso Polynomial  0.005622   -69.703680\n",
      "15      ElasticNet Polynomial  0.005645   -73.241404\n"
     ]
    }
   ],
   "source": [
    "new_result_MAE = pd.DataFrame(new_results[\"MAE\"])\n",
    "new_result_RMSE = pd.DataFrame(new_results[\"RMSE\"])\n",
    "new_result_R2 = pd.DataFrame(new_results[\"R2\"])\n",
    "\n",
    "print(\"\\nMAE Results:\\n\", new_result_MAE)\n",
    "print(\"\\nRMSE Results:\\n\", new_result_RMSE)\n",
    "print(\"\\nR2 Results:\\n\", new_result_R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Native models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in results:\n",
    "    mean_train = np.mean(results[metric]['Train'])\n",
    "    median_train = np.median(results[metric]['Train'])\n",
    "\n",
    "    mean_test = np.mean(results[metric]['Test'])\n",
    "    median_test = np.median(results[metric]['Test'])\n",
    "\n",
    "    results[metric]['Model'].append('Native mean')\n",
    "    results[metric]['Train'].append(mean_train)\n",
    "    results[metric]['Test'].append(mean_test)\n",
    "\n",
    "    results[metric]['Model'].append('Native median')\n",
    "    results[metric]['Train'].append(median_train)\n",
    "    results[metric]['Test'].append(median_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAE Results:\n",
      "                         Model        Train         Test\n",
      "0              Linreg Default  1135.890034  1123.607781\n",
      "1               Ridge Default  1135.844098  1123.574955\n",
      "2               Lasso Default  1132.050014  1120.776753\n",
      "3          ElasticNet Default  1090.801634  1108.878278\n",
      "4         Linreg MinMaxScaler  1135.890034  1123.607781\n",
      "5          Ridge MinMaxScaler  1135.838563  1123.883187\n",
      "6          Lasso MinMaxScaler  1131.372213  1120.726491\n",
      "7     ElasticNet MinMaxScaler  1436.094703  1389.342907\n",
      "8       Linreg StandardScaler  1135.890034  1123.607781\n",
      "9        Ridge StandardScaler  1135.879137  1123.599364\n",
      "10       Lasso StandardScaler  1134.175075  1122.270001\n",
      "11  ElasticNet StandardScaler  1051.474456  1066.145360\n",
      "12                Native mean  1149.266666  1139.168387\n",
      "13              Native median  1135.841331  1123.587160\n",
      "\n",
      "RMSE Results:\n",
      "                         Model         Train         Test\n",
      "0              Linreg Default  21992.794926  9618.787306\n",
      "1               Ridge Default  21992.794927  9618.778133\n",
      "2               Lasso Default  21992.804021  9618.658296\n",
      "3          ElasticNet Default  22012.208427  9613.895725\n",
      "4         Linreg MinMaxScaler  21992.794926  9618.787306\n",
      "5          Ridge MinMaxScaler  21992.797204  9617.988714\n",
      "6          Lasso MinMaxScaler  21992.812869  9617.142573\n",
      "7     ElasticNet MinMaxScaler  22050.168464  9685.211665\n",
      "8       Linreg StandardScaler  21992.794926  9618.787306\n",
      "9        Ridge StandardScaler  21992.794926  9618.785232\n",
      "10       Lasso StandardScaler  21992.796297  9618.708951\n",
      "11  ElasticNet StandardScaler  21998.635174  9602.965420\n",
      "12                Native mean  21999.683091  9622.374719\n",
      "13              Native median  21992.796750  9618.743542\n",
      "\n",
      "R2 Results:\n",
      "                         Model     Train      Test\n",
      "0              Linreg Default  0.006682  0.019311\n",
      "1               Ridge Default  0.006682  0.019312\n",
      "2               Lasso Default  0.006681  0.019337\n",
      "3          ElasticNet Default  0.004928  0.020308\n",
      "4         Linreg MinMaxScaler  0.006682  0.019311\n",
      "5          Ridge MinMaxScaler  0.006682  0.019473\n",
      "6          Lasso MinMaxScaler  0.006680  0.019646\n",
      "7     ElasticNet MinMaxScaler  0.001493  0.005719\n",
      "8       Linreg StandardScaler  0.006682  0.019311\n",
      "9        Ridge StandardScaler  0.006682  0.019311\n",
      "10       Lasso StandardScaler  0.006682  0.019327\n",
      "11  ElasticNet StandardScaler  0.006154  0.022534\n",
      "12                Native mean  0.006059  0.018575\n",
      "13              Native median  0.006682  0.019320\n"
     ]
    }
   ],
   "source": [
    "result_MAE = pd.DataFrame(results[\"MAE\"])\n",
    "result_RMSE = pd.DataFrame(results[\"RMSE\"])\n",
    "result_R2 = pd.DataFrame(results[\"R2\"])\n",
    "\n",
    "print(\"\\nMAE Results:\\n\", result_MAE)\n",
    "print(\"\\nRMSE Results:\\n\", result_RMSE)\n",
    "print(\"\\nR2 Results:\\n\", result_R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model (Overall): ElasticNet StandardScaler\n",
      "Most Stable Model: Native mean\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Determine the best model (lowest MAE and RMSE, highest R2)\n",
    "best_mae_model = result_MAE.loc[result_MAE['Test'].idxmin()]\n",
    "best_rmse_model = result_RMSE.loc[result_RMSE['Test'].idxmin()]\n",
    "best_r2_model = result_R2.loc[result_R2['Test'].idxmax()]\n",
    "\n",
    "# Calculate the overall ranking of models based on MAE, RMSE, and R2\n",
    "mae_rank = result_MAE['Test'].rank()\n",
    "rmse_rank = result_RMSE['Test'].rank()\n",
    "r2_rank = result_R2['Test'].rank(ascending=False)  # Higher R2 is better, so rank in descending order\n",
    "\n",
    "# Add ranks to the DataFrames for comparison\n",
    "result_MAE['Rank'] = mae_rank\n",
    "result_RMSE['Rank'] = rmse_rank\n",
    "result_R2['Rank'] = r2_rank\n",
    "\n",
    "# Combine ranks for the overall model rank\n",
    "combined_rank = (result_MAE['Rank'] + result_RMSE['Rank'] + result_R2['Rank']) / 3\n",
    "\n",
    "# Find the model with the lowest combined rank\n",
    "best_model_overall = result_MAE.iloc[combined_rank.idxmin()]\n",
    "\n",
    "print(f\"\\nBest Model (Overall): {best_model_overall['Model']}\")\n",
    "\n",
    "# Determine the most stable model (smallest difference between train and test)\n",
    "stability = result_MAE['Train'] - result_MAE['Test']\n",
    "most_stable_model = result_MAE.iloc[stability.abs().idxmin()]\n",
    "\n",
    "print(f\"Most Stable Model: {most_stable_model['Model']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Addition Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why Apply Log Transformation?**\n",
    "\n",
    "**Reduces Skewness:**\n",
    "\n",
    "- If the target variable has a right-skewed (long-tailed) distribution, taking the logarithm makes it closer to a normal distribution, which many machine learning models handle better.\n",
    "\n",
    "**Stabilizes Variance:**\n",
    "\n",
    "- Reduces the impact of outliers by compressing large values.\n",
    "\n",
    "**Improves Model Performance:**\n",
    "\n",
    "- Many regression models (like Linear Regression) assume homoscedasticity (constant variance). Log transformation helps satisfy this assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Log-transformed): 20906901046043.13\n",
      "RMSE (Log-transformed): 5712559650092251.0\n",
      "R² (Log-transformed): -3.4590141858145414e+23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "# Apply log transformation to target\n",
    "y_train_log = np.log(y_train)\n",
    "y_test_log = np.log(y_test)\n",
    "\n",
    "model_log = LinearRegression()\n",
    "model_log.fit(X_train, y_train_log)\n",
    "\n",
    "# Make predictions on the test set (in the log-transformed space)\n",
    "y_pred_log = model_log.predict(X_test)\n",
    "\n",
    "# Inverse transformation to get predictions back to the original scale\n",
    "y_pred = np.exp(y_pred_log)\n",
    "\n",
    "# Metrics\n",
    "mae_log = mean_absolute_error(y_test, y_pred)\n",
    "rmse_log = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2_log = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE (Log-transformed): {mae_log}\")\n",
    "print(f\"RMSE (Log-transformed): {rmse_log}\")\n",
    "print(f\"R² (Log-transformed): {r2_log}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove outliers from Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why Remove Outliers Only from Training Data?**\n",
    "\n",
    "\n",
    "**Prevent Model Bias**\n",
    "\n",
    "- Outliers pull the regression line towards them, leading to a biased model that does not generalize well.\n",
    "- By removing outliers from training data, we allow the model to learn a more stable, representative relationship between features and target variables.\n",
    "\n",
    "**Maintain Real-World Testing Conditions**\n",
    "\n",
    "- If you remove outliers from the test set, you create a false sense of model performance.\n",
    "- The model should be evaluated on real-world data, which includes outliers, since they may appear when making future predictions.\n",
    "\n",
    "**Avoid Data Leakage**\n",
    "\n",
    "- Removing outliers from both training and test sets could introduce data leakage, making the model artificially accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Cleaned Training Data): 953.758551133676\n",
      "RMSE (Cleaned Training Data): 9614.606682368274\n",
      "R² (Cleaned Training Data): 0.020162870226281715\n"
     ]
    }
   ],
   "source": [
    "# Calculate IQR for the target variable\n",
    "Q1 = np.percentile(y_train, 25)\n",
    "Q3 = np.percentile(y_train, 75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define bounds for outliers (outside 1.5*IQR range)\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Remove outliers from training data\n",
    "mask = (y_train >= lower_bound) & (y_train <= upper_bound)\n",
    "X_train_clean, y_train_clean = X_train[mask], y_train[mask]\n",
    "\n",
    "# Train model on the cleaned training data\n",
    "model_clean = LinearRegression()\n",
    "model_clean.fit(X_train_clean, y_train_clean)\n",
    "\n",
    "# Make predictions on the test set (no outliers removed from test data)\n",
    "y_pred_clean = model_clean.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae_clean = mean_absolute_error(y_test, y_pred_clean)\n",
    "rmse_clean = np.sqrt(mean_squared_error(y_test, y_pred_clean))\n",
    "r2_clean = r2_score(y_test, y_pred_clean)\n",
    "\n",
    "print(f\"MAE (Cleaned Training Data): {mae_clean}\")\n",
    "print(f\"RMSE (Cleaned Training Data): {rmse_clean}\")\n",
    "print(f\"R² (Cleaned Training Data): {r2_clean}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing Linear Regression with Batch Training (Gradient Descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In **batch training**, the model updates its weights using the **entire dataset** (or a large subset) in each iteration. This is useful when working with large datasets and avoids the inefficiencies of updating after every single data point (as in stochastic gradient descent)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **linear regression equation** is:\n",
    "\n",
    "$$\n",
    "y = Xw + b\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $X$ is the feature matrix,\n",
    "- $w$ is the weight vector (coefficients),\n",
    "- $b$ is the bias (intercept),\n",
    "- $y$ is the target variable.\n",
    "\n",
    "To find the best parameters $w$ and $b$, we minimize the **Mean Squared Error (MSE)**:\n",
    "\n",
    "$${MSE} = \\frac{1}{m} \\sum (y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "where $m$ is the number of samples.\n",
    "\n",
    "**Implement Batch Gradient Descent**\n",
    "\n",
    "Update rules:\n",
    "\n",
    "$$w = w - \\alpha \\frac{1}{m} X^T (Xw + b - y)$$\n",
    "\n",
    "$$b = b - \\alpha \\frac{1}{m} \\sum (Xw + b - y)$$\n",
    "\n",
    "where $\\alpha$ (alpha) is the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Batch Gradient Descent): 1112.0820351168907\n",
      "RMSE (Batch Gradient Descent): 9611.092557891541\n",
      "R² (Batch Gradient Descent): 0.0208789973648551\n"
     ]
    }
   ],
   "source": [
    "class BatchLinearRegression:\n",
    "    def __init__(self, learning_rate=0.01, epochs=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape\n",
    "        self.weights = np.zeros(n)\n",
    "        self.bias = 0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            y_pred = np.dot(X, self.weights) + self.bias\n",
    "\n",
    "            # Compute gradients\n",
    "            dw = (1 / m) * np.dot(X.T, (y_pred - y))\n",
    "            db = (1 / m) * np.sum(y_pred - y)\n",
    "\n",
    "            # Update weights and bias\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "\n",
    "# Train model using batch gradient descent\n",
    "model_batch = BatchLinearRegression(learning_rate=0.01, epochs=1000)\n",
    "model_batch.fit(X_train, y_train)\n",
    "\n",
    "y_pred_batch = model_batch.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "mae_batch = mean_absolute_error(y_test, y_pred_batch)\n",
    "rmse_batch = np.sqrt(mean_squared_error(y_test, y_pred_batch))\n",
    "r2_batch = r2_score(y_test, y_pred_batch)\n",
    "\n",
    "print(f\"MAE (Batch Gradient Descent): {mae_batch}\")\n",
    "print(f\"RMSE (Batch Gradient Descent): {rmse_batch}\")\n",
    "print(f\"R² (Batch Gradient Descent): {r2_batch}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
