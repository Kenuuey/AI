{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YD8VVw_kNyvO",
        "gwRT-ZLHNw5Q",
        "fItg_qsiC5TU",
        "eIln933QbO4H",
        "BT-YWYCmbTY_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "YD8VVw_kNyvO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y0IWqaXP49qo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "gwRT-ZLHNw5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "TYNB61uRRT59"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading"
      ],
      "metadata": {
        "id": "yQ1Sd7f9KMQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = './drive/MyDrive/Projects/data/DS_2/'\n",
        "train = pd.read_csv(path + 'bank_data_train.csv')\n",
        "test = pd.read_csv(path + 'bank_data_test.csv')"
      ],
      "metadata": {
        "id": "7ndtmnhaBY39"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = 'TARGET'"
      ],
      "metadata": {
        "id": "-c0hgEP0JUf0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape, test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IPNjpwFJPHj",
        "outputId": "4359eb66-a2e7-465b-9dc9-ae7a81c55cd9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(355190, 116) (88798, 116)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train[target].value_counts(normalize=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3WwuoeMNW_X",
        "outputId": "86b79503-e10c-4ecd-ac19-af2b2d80d318"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TARGET\n",
            "0    0.918565\n",
            "1    0.081435\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting"
      ],
      "metadata": {
        "id": "IvYXqHv4STva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = train.drop(columns=target)\n",
        "y = train[target]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "X_test = test.drop(columns=target)\n",
        "y_test = test[target]"
      ],
      "metadata": {
        "id": "kT8p1y7QJmlT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filling missing values"
      ],
      "metadata": {
        "id": "XCr-HBzOLF3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = X_train.select_dtypes(exclude='object').columns.tolist()\n",
        "cat_cols = X_train.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "num_imputer = SimpleImputer(strategy='median')\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "X_train[num_cols] = num_imputer.fit_transform(X_train[num_cols])\n",
        "X_val[num_cols] = num_imputer.transform(X_val[num_cols])\n",
        "X_test[num_cols] = num_imputer.transform(X_test[num_cols])\n",
        "\n",
        "X_train[cat_cols] = cat_imputer.fit_transform(X_train[cat_cols])\n",
        "X_val[cat_cols] = cat_imputer.transform(X_val[cat_cols])\n",
        "X_test[cat_cols] = cat_imputer.transform(X_test[cat_cols])"
      ],
      "metadata": {
        "id": "g4XuQVCCJ7k6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode categorical features with frequency encoding"
      ],
      "metadata": {
        "id": "dbD6_iZ3LKru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in cat_cols:\n",
        "    freq = X_train[col].value_counts(normalize=True)\n",
        "    X_train[col] = X_train[col].map(freq)\n",
        "    X_val[col] = X_val[col].map(freq).fillna(0)\n",
        "    X_test[col] = test[col].map(freq).fillna(0)"
      ],
      "metadata": {
        "id": "sJsH9m-GSPTH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling outliers"
      ],
      "metadata": {
        "id": "tKIxMoP3LM2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in num_cols:\n",
        "    Q1 = X_train[col].quantile(0.25)\n",
        "    Q3 = X_train[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "    X_train[col] = X_train[col].clip(lower, upper)\n",
        "    X_val[col] = X_val[col].clip(lower, upper)\n",
        "    X_test[col] = X_test[col].clip(lower, upper)"
      ],
      "metadata": {
        "id": "3OIbnLXlU7L_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling"
      ],
      "metadata": {
        "id": "hIHmZDq2LRPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
        "X_val = pd.DataFrame(scaler.transform(X_val), columns=X_val.columns)\n",
        "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
      ],
      "metadata": {
        "id": "A9wlyNvYVtK8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Selection"
      ],
      "metadata": {
        "id": "EcprucrIOrQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "selector = SelectFromModel(model, prefit=True)\n",
        "\n",
        "X_train_selected = selector.transform(X_train)\n",
        "X_val_selected = selector.transform(X_val)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "X_train.columns[selector.get_support()]"
      ],
      "metadata": {
        "id": "cew1jXoTOnII",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71a7d0a5-8f72-4865-a072-1da70ef98197"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ID', 'AMOUNT_RUB_CLO_PRC', 'AMOUNT_RUB_SUP_PRC', 'CLNT_TRUST_RELATION',\n",
              "       'APP_MARITAL_STATUS', 'REST_AVG_CUR', 'APP_KIND_OF_PROP_HABITATION',\n",
              "       'CLNT_JOB_POSITION_TYPE', 'AMOUNT_RUB_NAS_PRC', 'CLNT_JOB_POSITION',\n",
              "       'APP_DRIVING_LICENSE', 'TRANS_COUNT_SUP_PRC', 'APP_EDUCATION',\n",
              "       'TRANS_COUNT_NAS_PRC', 'APP_TRAVEL_PASS', 'CR_PROD_CNT_TOVR', 'APP_CAR',\n",
              "       'APP_POSITION_TYPE', 'TRANS_COUNT_ATM_PRC', 'AMOUNT_RUB_ATM_PRC', 'AGE',\n",
              "       'APP_EMP_TYPE', 'REST_DYNAMIC_CUR_1M', 'APP_COMP_TYPE',\n",
              "       'REST_DYNAMIC_CUR_3M', 'CNT_TRAN_SUP_TENDENCY3M',\n",
              "       'TURNOVER_DYNAMIC_CUR_1M', 'SUM_TRAN_SUP_TENDENCY3M',\n",
              "       'CNT_TRAN_ATM_TENDENCY3M', 'CNT_TRAN_ATM_TENDENCY1M',\n",
              "       'SUM_TRAN_ATM_TENDENCY3M', 'SUM_TRAN_ATM_TENDENCY1M',\n",
              "       'TURNOVER_DYNAMIC_CUR_3M', 'PACK', 'CLNT_SETUP_TENOR',\n",
              "       'TRANS_AMOUNT_TENDENCY3M', 'TRANS_CNT_TENDENCY3M'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Models"
      ],
      "metadata": {
        "id": "pTERY3hVWLFg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Classifier"
      ],
      "metadata": {
        "id": "Y3v-XaaCC3M2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy = DummyClassifier(strategy='most_frequent')\n",
        "dummy.fit(X_train_selected, y_train)\n",
        "y_pred_dummy = dummy.predict(X_val_selected)\n",
        "y_proba_dummy = dummy.predict_proba(X_val_selected)[:, 1]\n",
        "\n",
        "print(\"Dummy Classifier metrics:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred_dummy))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_val, y_proba_dummy))\n",
        "print(classification_report(y_val, y_pred_dummy))"
      ],
      "metadata": {
        "id": "EEWG82bVbDgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94e0eae5-5ee8-4f23-a0d1-f11316653ea6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy Classifier metrics:\n",
            "Accuracy: 0.918564711844365\n",
            "ROC AUC: 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96     65253\n",
            "           1       0.00      0.00      0.00      5785\n",
            "\n",
            "    accuracy                           0.92     71038\n",
            "   macro avg       0.46      0.50      0.48     71038\n",
            "weighted avg       0.84      0.92      0.88     71038\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "dS6iuSQZE-GF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [20, 30],\n",
        "    'max_depth': [5, 10],\n",
        "    'class_weight': ['balanced', None]\n",
        "}\n",
        "\n",
        "grid_rf = GridSearchCV(rf, param_grid, cv=2, scoring='roc_auc', verbose=1)\n",
        "\n",
        "start_time = time.time()\n",
        "grid_rf.fit(X_train_selected, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Random Forest GridSearch done in {end_time - start_time:.2f}s\")\n",
        "print(\"Best params:\", grid_rf.best_params_)\n",
        "\n",
        "best_rf = grid_rf.best_estimator_\n",
        "y_pred_rf = best_rf.predict(X_val_selected)\n",
        "y_proba_rf = best_rf.predict_proba(X_val_selected)[:, 1]\n",
        "\n",
        "print(\"Random Forest metrics:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred_rf))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_val, y_proba_rf))\n",
        "print(classification_report(y_val, y_pred_rf))"
      ],
      "metadata": {
        "id": "XF_LsgzgbFOQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3a2c1ab-28ea-4117-b1b0-d1a7c7305a1d"
      },
      "execution_count": 68,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
            "Random Forest GridSearch done in 110.65s\n",
            "Best params: {'class_weight': None, 'max_depth': 10, 'n_estimators': 30}\n",
            "Random Forest metrics:\n",
            "Accuracy: 0.9185787888172527\n",
            "ROC AUC: 0.8050296140727214\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96     65253\n",
            "           1       0.67      0.00      0.00      5785\n",
            "\n",
            "    accuracy                           0.92     71038\n",
            "   macro avg       0.79      0.50      0.48     71038\n",
            "weighted avg       0.90      0.92      0.88     71038\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Metric              | Value  | What it means                                       |\n",
        "| ------------------- | ------ | --------------------------------------------------- |\n",
        "| Accuracy            | 0.9186 | \\~92% overall correct predictions                   |\n",
        "| ROC AUC             | 0.8050 | Good discrimination ability (0.5=chance, 1=perfect) |\n",
        "| Precision (class 0) | 0.92   | Of predicted non-churn, 92% correct                 |\n",
        "| Recall (class 0)    | 1.00   | Model found almost all non-churn cases              |\n",
        "| Precision (class 1) | 0.67   | Of predicted churn, 67% correct                     |\n",
        "| Recall (class 1)    | 0.00   | Model detected almost **no churn cases** (bad)      |\n"
      ],
      "metadata": {
        "id": "ZyEv2Z4lZNSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_proba_rf = best_rf.predict_proba(X_test_selected)[:, 1]\n",
        "# print(f\"Test ROC AUC: {roc_auc_score(y_test, y_test_proba_rf):.4f}\")"
      ],
      "metadata": {
        "id": "DlfgPA3eZVP9"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scikit-learn MLPClassifier"
      ],
      "metadata": {
        "id": "fItg_qsiC5TU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(64,), (128,)],\n",
        "    'alpha': [1e-4, 1e-3],\n",
        "    'learning_rate': ['adaptive'],\n",
        "    'learning_rate_init': [0.001],\n",
        "    'activation': ['relu'],\n",
        "    'solver': ['adam']\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    MLPClassifier(max_iter=300, early_stopping=True, random_state=42),\n",
        "    param_grid,\n",
        "    cv=cv,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "grid.fit(X_train_selected, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"MLPClassifier training time: {end_time - start_time:.2f}s\")\n",
        "\n",
        "best_mlp = grid.best_estimator_\n",
        "y_pred_mlp = best_mlp.predict(X_val_selected)\n",
        "y_proba_mlp = best_mlp.predict_proba(X_val_selected)[:, 1]\n",
        "\n",
        "print(\"MLPClassifier metrics:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred_mlp))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_val, y_proba_mlp))\n",
        "print(classification_report(y_val, y_pred_mlp))"
      ],
      "metadata": {
        "id": "nPrWGyFwbHR4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c14f22b-2f57-47ca-c3c9-ebf732d0905e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "MLPClassifier training time: 104.96s\n",
            "MLPClassifier metrics:\n",
            "Accuracy: 0.9185365578985895\n",
            "ROC AUC: 0.7575291312435776\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96     65253\n",
            "           1       0.38      0.00      0.00      5785\n",
            "\n",
            "    accuracy                           0.92     71038\n",
            "   macro avg       0.65      0.50      0.48     71038\n",
            "weighted avg       0.87      0.92      0.88     71038\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras (TensorFlow High-Level API)"
      ],
      "metadata": {
        "id": "sJv2gyGlYC8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = X_train_selected.shape[1]\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(input_dim,)),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "\n",
        "start_time = time.time()\n",
        "history = model.fit(\n",
        "    X_train_selected, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_val_selected, y_val),\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Keras model training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "y_proba_keras = model.predict(X_val_selected).flatten()\n",
        "y_pred_keras = (y_proba_keras > 0.5).astype(int)\n",
        "\n",
        "print(\"Keras MLP metrics:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred_keras))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_val, y_proba_keras))\n",
        "print(classification_report(y_val, y_pred_keras))"
      ],
      "metadata": {
        "id": "7yeyZM4qbI7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "f26ac907-847d-410c-dbe0-986c37925479"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9139 - loss: 0.2884 - val_accuracy: 0.9186 - val_loss: 0.2537 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9188 - loss: 0.2564 - val_accuracy: 0.9186 - val_loss: 0.2503 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.9184 - loss: 0.2517 - val_accuracy: 0.9186 - val_loss: 0.2459 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9183 - loss: 0.2496 - val_accuracy: 0.9186 - val_loss: 0.2452 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9189 - loss: 0.2467 - val_accuracy: 0.9186 - val_loss: 0.2435 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9193 - loss: 0.2435 - val_accuracy: 0.9186 - val_loss: 0.2413 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9192 - loss: 0.2423 - val_accuracy: 0.9186 - val_loss: 0.2402 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9182 - loss: 0.2433 - val_accuracy: 0.9186 - val_loss: 0.2401 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9184 - loss: 0.2428 - val_accuracy: 0.9186 - val_loss: 0.2403 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9188 - loss: 0.2423 - val_accuracy: 0.9186 - val_loss: 0.2395 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9190 - loss: 0.2413 - val_accuracy: 0.9186 - val_loss: 0.2384 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.2405 - val_accuracy: 0.9186 - val_loss: 0.2390 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9183 - loss: 0.2423 - val_accuracy: 0.9186 - val_loss: 0.2393 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m4422/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9190 - loss: 0.2395\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9190 - loss: 0.2395 - val_accuracy: 0.9186 - val_loss: 0.2388 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - accuracy: 0.9182 - loss: 0.2402 - val_accuracy: 0.9186 - val_loss: 0.2369 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9190 - loss: 0.2373 - val_accuracy: 0.9186 - val_loss: 0.2366 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9190 - loss: 0.2377 - val_accuracy: 0.9186 - val_loss: 0.2367 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9180 - loss: 0.2385 - val_accuracy: 0.9186 - val_loss: 0.2360 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9184 - loss: 0.2372 - val_accuracy: 0.9186 - val_loss: 0.2361 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9191 - loss: 0.2362 - val_accuracy: 0.9186 - val_loss: 0.2361 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m4428/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9186 - loss: 0.2367\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2367 - val_accuracy: 0.9185 - val_loss: 0.2368 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9183 - loss: 0.2368 - val_accuracy: 0.9186 - val_loss: 0.2355 - learning_rate: 2.5000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9183 - loss: 0.2367 - val_accuracy: 0.9186 - val_loss: 0.2352 - learning_rate: 2.5000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9192 - loss: 0.2350 - val_accuracy: 0.9186 - val_loss: 0.2354 - learning_rate: 2.5000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.2355 - val_accuracy: 0.9186 - val_loss: 0.2357 - learning_rate: 2.5000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9171 - loss: 0.2386 - val_accuracy: 0.9186 - val_loss: 0.2351 - learning_rate: 2.5000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9189 - loss: 0.2351 - val_accuracy: 0.9186 - val_loss: 0.2351 - learning_rate: 2.5000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9189 - loss: 0.2344 - val_accuracy: 0.9186 - val_loss: 0.2351 - learning_rate: 2.5000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.2359 - val_accuracy: 0.9185 - val_loss: 0.2348 - learning_rate: 2.5000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9181 - loss: 0.2363 - val_accuracy: 0.9186 - val_loss: 0.2351 - learning_rate: 2.5000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9194 - loss: 0.2337 - val_accuracy: 0.9186 - val_loss: 0.2352 - learning_rate: 2.5000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m4427/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9189 - loss: 0.2354\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9189 - loss: 0.2354 - val_accuracy: 0.9186 - val_loss: 0.2351 - learning_rate: 2.5000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9190 - loss: 0.2353 - val_accuracy: 0.9186 - val_loss: 0.2347 - learning_rate: 1.2500e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9192 - loss: 0.2338 - val_accuracy: 0.9186 - val_loss: 0.2348 - learning_rate: 1.2500e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m4431/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.2349\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9188 - loss: 0.2349 - val_accuracy: 0.9186 - val_loss: 0.2347 - learning_rate: 1.2500e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2352 - val_accuracy: 0.9186 - val_loss: 0.2346 - learning_rate: 6.2500e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9181 - loss: 0.2351 - val_accuracy: 0.9186 - val_loss: 0.2345 - learning_rate: 6.2500e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9181 - loss: 0.2349 - val_accuracy: 0.9186 - val_loss: 0.2346 - learning_rate: 6.2500e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.2338 - val_accuracy: 0.9186 - val_loss: 0.2346 - learning_rate: 6.2500e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m4429/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.2343\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9184 - loss: 0.2343 - val_accuracy: 0.9185 - val_loss: 0.2345 - learning_rate: 6.2500e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.2349 - val_accuracy: 0.9186 - val_loss: 0.2345 - learning_rate: 3.1250e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2345 - val_accuracy: 0.9186 - val_loss: 0.2344 - learning_rate: 3.1250e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m4417/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9181 - loss: 0.2341\n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.9181 - loss: 0.2341 - val_accuracy: 0.9185 - val_loss: 0.2345 - learning_rate: 3.1250e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9190 - loss: 0.2338 - val_accuracy: 0.9185 - val_loss: 0.2345 - learning_rate: 1.5625e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9179 - loss: 0.2363 - val_accuracy: 0.9185 - val_loss: 0.2345 - learning_rate: 1.5625e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m4428/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2350\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9183 - loss: 0.2350 - val_accuracy: 0.9185 - val_loss: 0.2345 - learning_rate: 1.5625e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9179 - loss: 0.2368 - val_accuracy: 0.9185 - val_loss: 0.2345 - learning_rate: 7.8125e-06\n",
            "Keras model training time: 823.34 seconds\n",
            "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
            "Keras MLP metrics:\n",
            "Accuracy: 0.9185506348714773\n",
            "ROC AUC: 0.8050115883630448\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96     65253\n",
            "           1       0.44      0.00      0.00      5785\n",
            "\n",
            "    accuracy                           0.92     71038\n",
            "   macro avg       0.68      0.50      0.48     71038\n",
            "weighted avg       0.88      0.92      0.88     71038\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow (Low-Level API)"
      ],
      "metadata": {
        "id": "p_WSCzjNYHgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight"
      ],
      "metadata": {
        "id": "COjifAIP02EO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_convert_X(X):\n",
        "    if hasattr(X, \"to_numpy\"):\n",
        "        return X.to_numpy().astype(np.float32)\n",
        "    else:\n",
        "        return X.astype(np.float32)\n",
        "\n",
        "def safe_convert_y(y):\n",
        "    if hasattr(y, \"to_numpy\"):\n",
        "        return y.to_numpy().astype(np.float32).reshape(-1, 1)\n",
        "    else:\n",
        "        return y.astype(np.float32).reshape(-1, 1)\n",
        "\n",
        "X_train = safe_convert_X(X_train)\n",
        "y_train = safe_convert_y(y_train)\n",
        "X_val = safe_convert_X(X_val)\n",
        "y_val = safe_convert_y(y_val)\n",
        "\n",
        "print(\"Train class distribution:\", np.bincount(y_train.flatten().astype(int)))\n",
        "print(\"Val class distribution:\", np.bincount(y_val.flatten().astype(int)))"
      ],
      "metadata": {
        "id": "J_VCBu970b6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)) \\\n",
        "    .shuffle(buffer_size=10000) \\\n",
        "    .batch(batch_size) \\\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)) \\\n",
        "    .batch(batch_size) \\\n",
        "    .prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "gmcakr4F0sGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleMLP(tf.Module):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.dense1 = tf.Variable(tf.random.normal([X_train.shape[1], 64]), name=\"dense1_weights\")\n",
        "        self.bias1 = tf.Variable(tf.zeros([64]), name=\"dense1_bias\")\n",
        "\n",
        "        self.dense2 = tf.Variable(tf.random.normal([64, 32]), name=\"dense2_weights\")\n",
        "        self.bias2 = tf.Variable(tf.zeros([32]), name=\"dense2_bias\")\n",
        "\n",
        "        self.out = tf.Variable(tf.random.normal([32, 1]), name=\"out_weights\")\n",
        "        self.out_bias = tf.Variable(tf.zeros([1]), name=\"out_bias\")\n",
        "\n",
        "    def __call__(self, x, training=False):\n",
        "        x = tf.matmul(x, self.dense1) + self.bias1\n",
        "        x = tf.nn.relu(x)\n",
        "        if training:\n",
        "            x = tf.nn.dropout(x, rate=0.3)\n",
        "\n",
        "        x = tf.matmul(x, self.dense2) + self.bias2\n",
        "        x = tf.nn.relu(x)\n",
        "        if training:\n",
        "            x = tf.nn.dropout(x, rate=0.3)\n",
        "\n",
        "        x = tf.matmul(x, self.out) + self.out_bias\n",
        "        return tf.sigmoid(x)"
      ],
      "metadata": {
        "id": "KE-joqHb0qOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleMLP()\n",
        "\n",
        "y_train_1d = y_train.flatten().astype(int)\n",
        "weights = class_weight.compute_class_weight(class_weight='balanced',\n",
        "                                            classes=np.unique(y_train_1d),\n",
        "                                            y=y_train_1d)\n",
        "class_weights_tf = {\n",
        "    int(cls): tf.constant(w, dtype=tf.float32)\n",
        "    for cls, w in zip(np.unique(y_train_1d), weights)\n",
        "}\n",
        "print(\"Computed class weights:\", class_weights_tf)\n",
        "\n",
        "def loss_fn(y_true, y_pred):\n",
        "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
        "    weights = tf.where(tf.equal(y_true, 1), class_weights_tf[1], class_weights_tf[0])\n",
        "    loss = -(weights * (y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred)))\n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "optimizer = tf.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "@tf.function\n",
        "def train_step(x_batch, y_batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = model(x_batch, training=True)\n",
        "        loss = loss_fn(y_batch, y_pred)\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "def validate():\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    val_losses = []\n",
        "    for x_batch, y_batch in val_ds:\n",
        "        y_pred = model(x_batch, training=False)\n",
        "        val_losses.append(loss_fn(y_batch, y_pred).numpy())\n",
        "        all_preds.append(y_pred.numpy())\n",
        "        all_labels.append(y_batch.numpy())\n",
        "    val_loss = np.mean(val_losses)\n",
        "    all_preds = np.vstack(all_preds).flatten()\n",
        "    all_labels = np.vstack(all_labels).flatten()\n",
        "    return val_loss, all_labels, all_preds\n",
        "\n",
        "# --- Training loop with early stopping ---\n",
        "epochs = 50\n",
        "patience = 5\n",
        "best_val_loss = np.inf\n",
        "wait = 0\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    train_losses = []\n",
        "    for x_batch, y_batch in train_ds:\n",
        "        loss = train_step(x_batch, y_batch)\n",
        "        train_losses.append(loss.numpy())\n",
        "\n",
        "    train_loss_avg = np.mean(train_losses)\n",
        "    val_loss, y_val_true, y_val_pred = validate()\n",
        "\n",
        "    val_auc = roc_auc_score(y_val_true, y_val_pred)\n",
        "    val_acc = accuracy_score(y_val_true, y_val_pred > 0.5)\n",
        "    print(f\"Train loss: {train_loss_avg:.4f}, Val loss: {val_loss:.4f}, Val ROC AUC: {val_auc:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        wait = 0\n",
        "        best_weights = [v.numpy() for v in model.trainable_variables]\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Restore best weights after training ends\n",
        "for var, best_val in zip(model.trainable_variables, best_weights):\n",
        "    var.assign(best_val)\n",
        "\n",
        "# Final evaluation\n",
        "val_loss, y_val_true, y_val_pred = validate()\n",
        "y_val_pred_class = (y_val_pred > 0.5).astype(int)\n",
        "\n",
        "print(\"Final evaluation on validation set:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val_true, y_val_pred_class))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_val_true, y_val_pred))\n",
        "print(classification_report(y_val_true, y_val_pred_class))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SMwS9U4LlGam",
        "outputId": "6d58f14e-0fb4-4e01-b5e3-c14cfd912918"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "Train loss: 6.4537, Val loss: 5.3809, Val ROC AUC: 0.6543, Val Acc: 0.5650\n",
            "Epoch 2/50\n",
            "Train loss: 5.6510, Val loss: 4.7196, Val ROC AUC: 0.6853, Val Acc: 0.6234\n",
            "Epoch 3/50\n",
            "Train loss: 3.4375, Val loss: 0.6772, Val ROC AUC: 0.6644, Val Acc: 0.7572\n",
            "Epoch 4/50\n",
            "Train loss: 0.7182, Val loss: 0.6354, Val ROC AUC: 0.6955, Val Acc: 0.6827\n",
            "Epoch 5/50\n",
            "Train loss: 0.6490, Val loss: 0.6225, Val ROC AUC: 0.7151, Val Acc: 0.5223\n",
            "Epoch 6/50\n",
            "Train loss: 0.6289, Val loss: 0.6082, Val ROC AUC: 0.7258, Val Acc: 0.6046\n",
            "Epoch 7/50\n",
            "Train loss: 0.6194, Val loss: 0.6175, Val ROC AUC: 0.7337, Val Acc: 0.7014\n",
            "Epoch 8/50\n",
            "Train loss: 0.6144, Val loss: 0.6008, Val ROC AUC: 0.7412, Val Acc: 0.6430\n",
            "Epoch 9/50\n",
            "Train loss: 0.6114, Val loss: 0.5992, Val ROC AUC: 0.7445, Val Acc: 0.6257\n",
            "Epoch 10/50\n",
            "Train loss: 0.6071, Val loss: 0.6077, Val ROC AUC: 0.7460, Val Acc: 0.6927\n",
            "Epoch 11/50\n",
            "Train loss: 0.6037, Val loss: 0.6050, Val ROC AUC: 0.7478, Val Acc: 0.6475\n",
            "Epoch 12/50\n",
            "Train loss: 0.6005, Val loss: 0.5891, Val ROC AUC: 0.7512, Val Acc: 0.6295\n",
            "Epoch 13/50\n",
            "Train loss: 0.5941, Val loss: 0.5882, Val ROC AUC: 0.7541, Val Acc: 0.6281\n",
            "Epoch 14/50\n",
            "Train loss: 0.5946, Val loss: 0.5836, Val ROC AUC: 0.7569, Val Acc: 0.6047\n",
            "Epoch 15/50\n",
            "Train loss: 0.5907, Val loss: 0.5918, Val ROC AUC: 0.7583, Val Acc: 0.5934\n",
            "Epoch 16/50\n",
            "Train loss: 0.5877, Val loss: 0.5852, Val ROC AUC: 0.7565, Val Acc: 0.6375\n",
            "Epoch 17/50\n",
            "Train loss: 0.5826, Val loss: 0.5776, Val ROC AUC: 0.7664, Val Acc: 0.5262\n",
            "Epoch 18/50\n",
            "Train loss: 0.5795, Val loss: 0.5764, Val ROC AUC: 0.7667, Val Acc: 0.5272\n",
            "Epoch 19/50\n",
            "Train loss: 0.5772, Val loss: 0.5694, Val ROC AUC: 0.7704, Val Acc: 0.5374\n",
            "Epoch 20/50\n",
            "Train loss: 0.5744, Val loss: 0.5648, Val ROC AUC: 0.7726, Val Acc: 0.5260\n",
            "Epoch 21/50\n",
            "Train loss: 0.5722, Val loss: 0.5663, Val ROC AUC: 0.7753, Val Acc: 0.5289\n",
            "Epoch 22/50\n",
            "Train loss: 0.5702, Val loss: 0.5632, Val ROC AUC: 0.7752, Val Acc: 0.5336\n",
            "Epoch 23/50\n",
            "Train loss: 0.5665, Val loss: 0.5560, Val ROC AUC: 0.7776, Val Acc: 0.5447\n",
            "Epoch 24/50\n",
            "Train loss: 0.5640, Val loss: 0.5591, Val ROC AUC: 0.7805, Val Acc: 0.5387\n",
            "Epoch 25/50\n",
            "Train loss: 0.5635, Val loss: 0.5547, Val ROC AUC: 0.7828, Val Acc: 0.5389\n",
            "Epoch 26/50\n",
            "Train loss: 0.5617, Val loss: 0.5517, Val ROC AUC: 0.7850, Val Acc: 0.5456\n",
            "Epoch 27/50\n",
            "Train loss: 0.5599, Val loss: 0.5525, Val ROC AUC: 0.7840, Val Acc: 0.5278\n",
            "Epoch 28/50\n",
            "Train loss: 0.5574, Val loss: 0.5490, Val ROC AUC: 0.7868, Val Acc: 0.5638\n",
            "Epoch 29/50\n",
            "Train loss: 0.5553, Val loss: 0.5483, Val ROC AUC: 0.7865, Val Acc: 0.5450\n",
            "Epoch 30/50\n",
            "Train loss: 0.5528, Val loss: 0.5487, Val ROC AUC: 0.7876, Val Acc: 0.5455\n",
            "Epoch 31/50\n",
            "Train loss: 0.5519, Val loss: 0.5492, Val ROC AUC: 0.7889, Val Acc: 0.5435\n",
            "Epoch 32/50\n",
            "Train loss: 0.5508, Val loss: 0.5463, Val ROC AUC: 0.7911, Val Acc: 0.5485\n",
            "Epoch 33/50\n",
            "Train loss: 0.5495, Val loss: 0.5437, Val ROC AUC: 0.7910, Val Acc: 0.5719\n",
            "Epoch 34/50\n",
            "Train loss: 0.5484, Val loss: 0.5416, Val ROC AUC: 0.7915, Val Acc: 0.5687\n",
            "Epoch 35/50\n",
            "Train loss: 0.5476, Val loss: 0.5416, Val ROC AUC: 0.7911, Val Acc: 0.5678\n",
            "Epoch 36/50\n",
            "Train loss: 0.5462, Val loss: 0.5421, Val ROC AUC: 0.7919, Val Acc: 0.5624\n",
            "Epoch 37/50\n",
            "Train loss: 0.5445, Val loss: 0.5400, Val ROC AUC: 0.7945, Val Acc: 0.5828\n",
            "Epoch 38/50\n",
            "Train loss: 0.5441, Val loss: 0.5419, Val ROC AUC: 0.7919, Val Acc: 0.5629\n",
            "Epoch 39/50\n",
            "Train loss: 0.5438, Val loss: 0.5424, Val ROC AUC: 0.7937, Val Acc: 0.5768\n",
            "Epoch 40/50\n",
            "Train loss: 0.5425, Val loss: 0.5396, Val ROC AUC: 0.7941, Val Acc: 0.5618\n",
            "Epoch 41/50\n",
            "Train loss: 0.5433, Val loss: 0.5403, Val ROC AUC: 0.7942, Val Acc: 0.5632\n",
            "Epoch 42/50\n",
            "Train loss: 0.5410, Val loss: 0.5400, Val ROC AUC: 0.7950, Val Acc: 0.5756\n",
            "Epoch 43/50\n",
            "Train loss: 0.5408, Val loss: 0.5384, Val ROC AUC: 0.7955, Val Acc: 0.5768\n",
            "Epoch 44/50\n",
            "Train loss: 0.5404, Val loss: 0.5400, Val ROC AUC: 0.7945, Val Acc: 0.5676\n",
            "Epoch 45/50\n",
            "Train loss: 0.5401, Val loss: 0.5378, Val ROC AUC: 0.7958, Val Acc: 0.5705\n",
            "Epoch 46/50\n",
            "Train loss: 0.5411, Val loss: 0.5398, Val ROC AUC: 0.7960, Val Acc: 0.5753\n",
            "Epoch 47/50\n",
            "Train loss: 0.5399, Val loss: 0.5360, Val ROC AUC: 0.7975, Val Acc: 0.5896\n",
            "Epoch 48/50\n",
            "Train loss: 0.5383, Val loss: 0.5367, Val ROC AUC: 0.7966, Val Acc: 0.5799\n",
            "Epoch 49/50\n",
            "Train loss: 0.5376, Val loss: 0.5380, Val ROC AUC: 0.7973, Val Acc: 0.5784\n",
            "Epoch 50/50\n",
            "Train loss: 0.5376, Val loss: 0.5375, Val ROC AUC: 0.7962, Val Acc: 0.5798\n",
            "Training time: 1165.04 seconds\n",
            "Final evaluation on validation set:\n",
            "Accuracy: 0.5895717784847546\n",
            "ROC AUC: 0.7975105142577747\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.56      0.72     65253\n",
            "         1.0       0.15      0.89      0.26      5785\n",
            "\n",
            "    accuracy                           0.59     71038\n",
            "   macro avg       0.57      0.73      0.49     71038\n",
            "weighted avg       0.91      0.59      0.68     71038\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NumPy"
      ],
      "metadata": {
        "id": "81CmosoxZrC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NumpyMLP:\n",
        "    def __init__(self, input_dim, hidden1=64, hidden2=32, lr=0.001):\n",
        "        np.random.seed(42)\n",
        "        self.lr = lr\n",
        "        self.W1 = np.random.randn(input_dim, hidden1) * 0.01\n",
        "        self.b1 = np.zeros((1, hidden1))\n",
        "        self.W2 = np.random.randn(hidden1, hidden2) * 0.01\n",
        "        self.b2 = np.zeros((1, hidden2))\n",
        "        self.W3 = np.random.randn(hidden2, 1) * 0.01\n",
        "        self.b3 = np.zeros((1, 1))\n",
        "\n",
        "    def relu(self, x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def relu_deriv(self, x):\n",
        "        return (x > 0).astype(float)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.Z1 = X @ self.W1 + self.b1\n",
        "        self.A1 = self.relu(self.Z1)\n",
        "        self.Z2 = self.A1 @ self.W2 + self.b2\n",
        "        self.A2 = self.relu(self.Z2)\n",
        "        self.Z3 = self.A2 @ self.W3 + self.b3\n",
        "        self.A3 = self.sigmoid(self.Z3)\n",
        "        return self.A3\n",
        "\n",
        "    def backward(self, X, y, output):\n",
        "        m = y.shape[0]\n",
        "        dZ3 = output - y.reshape(-1, 1)\n",
        "        dW3 = (self.A2.T @ dZ3) / m\n",
        "        db3 = np.sum(dZ3, axis=0, keepdims=True) / m\n",
        "\n",
        "        dA2 = dZ3 @ self.W3.T\n",
        "        dZ2 = dA2 * self.relu_deriv(self.Z2)\n",
        "        dW2 = (self.A1.T @ dZ2) / m\n",
        "        db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
        "\n",
        "        dA1 = dZ2 @ self.W2.T\n",
        "        dZ1 = dA1 * self.relu_deriv(self.Z1)\n",
        "        dW1 = (X.T @ dZ1) / m\n",
        "        db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
        "\n",
        "        # Update weights\n",
        "        self.W3 -= self.lr * dW3\n",
        "        self.b3 -= self.lr * db3\n",
        "        self.W2 -= self.lr * dW2\n",
        "        self.b2 -= self.lr * db2\n",
        "        self.W1 -= self.lr * dW1\n",
        "        self.b1 -= self.lr * db1\n",
        "\n",
        "    def train(self, X, y, epochs=100, batch_size=64):\n",
        "        n = X.shape[0]\n",
        "        for epoch in range(epochs):\n",
        "            perm = np.random.permutation(n)\n",
        "            X_shuffled = X[perm]\n",
        "            y_shuffled = y[perm]\n",
        "            for i in range(0, n, batch_size):\n",
        "                X_batch = X_shuffled[i:i + batch_size]\n",
        "                y_batch = y_shuffled[i:i + batch_size]\n",
        "                output = self.forward(X_batch)\n",
        "                self.backward(X_batch, y_batch, output)\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                pred = self.forward(X)\n",
        "                loss = -np.mean(y * np.log(pred + 1e-8) + (1 - y) * np.log(1 - pred + 1e-8))\n",
        "                print(f\"Epoch {epoch + 1}/{epochs} - loss: {loss:.4f}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        prob = self.forward(X)\n",
        "        return (prob > 0.5).astype(int), prob\n",
        "\n",
        "# Train numpy MLP\n",
        "np_mlp = NumpyMLP(input_dim=X_train.shape[1], hidden1=64, hidden2=32, lr=0.001)\n",
        "\n",
        "X_train_np = X_train.values\n",
        "y_train_np = y_train.values\n",
        "\n",
        "np_mlp.train(X_train_np, y_train_np, epochs=50, batch_size=128)\n",
        "\n",
        "X_val_np = X_val.values\n",
        "y_pred_np, y_proba_np = np_mlp.predict(X_val_np)\n",
        "\n",
        "print(\"NumPy MLP metrics:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred_np))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_val, y_proba_np))\n",
        "print(classification_report(y_val, y_pred_np))"
      ],
      "metadata": {
        "id": "-iBgJ46fbM5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Final Predictions on Test Set (Using best model)"
      ],
      "metadata": {
        "id": "eIln933QbO4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Using Keras model for final prediction (you can choose your best model)\n",
        "\n",
        "test_proba = model.predict(test_scaled).flatten()\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test.index,\n",
        "    'TARGET': test_proba\n",
        "})\n",
        "\n",
        "submission.to_csv('final_predictions.csv', index=False)\n",
        "print(\"Saved final predictions to final_predictions.csv\")\n"
      ],
      "metadata": {
        "id": "EMA9aSYzbPTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary table format"
      ],
      "metadata": {
        "id": "BT-YWYCmbTY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame([\n",
        "    ['DummyClassifier', 'Most Frequent', '-', accuracy_score(y_val, y_pred_dummy), roc_auc_score(y_val, y_proba_dummy)],\n",
        "    ['RandomForest', str(grid_search.best_params_), '-', accuracy_score(y_val, y_pred_rf), roc_auc_score(y_val, y_proba_rf)],\n",
        "    ['MLPClassifier', 'hidden_layer_sizes=(64,32)', '-', accuracy_score(y_val, y_pred_mlp), roc_auc_score(y_val, y_proba_mlp)],\n",
        "    ['Keras', '64,32 + dropout', 'Adam lr=0.001', accuracy_score(y_val, y_pred_keras), roc_auc_score(y_val, y_proba_keras)],\n",
        "    ['TensorFlow', '64,32 + dropout', 'Adam lr=0.001', accuracy_score(y_val, y_pred_tf), roc_auc_score(y_val, y_proba_tf)],\n",
        "    ['NumPy', '64,32 (manual)', 'lr=0.001', accuracy_score(y_val, y_pred_np), roc_auc_score(y_val, y_proba_np)],\n",
        "], columns=['Library', 'Hyperparameters', 'Notes', 'Accuracy', 'ROC_AUC'])\n",
        "\n",
        "print(results)\n"
      ],
      "metadata": {
        "id": "ryFU4D9nbTIX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}